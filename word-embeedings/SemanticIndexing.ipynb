{
 "metadata": {
  "language": "Julia",
  "name": "",
  "signature": "sha256:cc466fe8e04f07ebe5416f3ea97d5863e161aa40134ca3b080a58396d69279c8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using Lazy\n",
      "using DataFrames\n",
      "using Memoize\n",
      "\n",
      "using Gadfly\n",
      "using Compose\n",
      "\n",
      "push!(LOAD_PATH, \"./TSne.jl/src/\")\n",
      "using TSne\n",
      "set_default_plot_size(30cm, 30cm)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "WARNING: deprecated syntax \"{}\" at /home/wheel/oxinabox/.julia/v0.4/Memoize/src/Memoize.jl:24.\n",
        "Use \"[]\" instead.\n",
        "Warning: Method definition take("
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Any,Int64) in module Base at iterator.jl:129 overwritten in module Iterators at /home/wheel/oxinabox/.julia/v0.4/Iterators/src/Iterators.jl:50.\n",
        "\n",
        "WARNING: deprecated syntax \"{}\" at /home/wheel/oxinabox/.julia/v0.4/Calculus/src/symbolic.jl:108.\n",
        "Use \"[]\" instead.\n",
        "\n",
        "WARNING: deprecated syntax \"{}\" at /home/wheel/oxinabox/.julia/v0.4/Calculus/src/symbolic.jl:121.\n",
        "Use \"[]\" instead.\n",
        "\n",
        "WARNING: deprecated syntax \"{a=>b, ...}\" at /home/wheel/oxinabox/.julia/v0.4/Calculus/src/deparse.jl:1.\n",
        "Use \"Dict{Any,Any}(a=>b, ...)\" instead.\n",
        "\n",
        "WARNING: deprecated syntax \"{a=>b, ...}\" at /home/wheel/oxinabox/.julia/v0.4/Optim/src/levenberg_marquardt.jl:41.\n",
        "Use \"Dict{Any,Any}(a=>b, ...)\" instead.\n",
        "\n",
        "WARNING: deprecated syntax \"{a=>b, ...}\" at /home/wheel/oxinabox/.julia/v0.4/Optim/src/levenberg_marquardt.jl:90.\n",
        "Use \"Dict{Any,Any}(a=>b, ...)\" instead.\n",
        "WARNING: [a] concatenation is deprecated; use [a;] instead"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        " in depwarn at ./deprecated.jl:40\n",
        " in oldstyle_vcat_warning at ./abstractarray.jl:26\n",
        " in vect at abstractarray.jl:29\n",
        " in include at ./boot.jl:249\n",
        " in include_from_node1 at ./loading.jl:128\n",
        " in include at ./boot.jl:249\n",
        " in include_from_node1 at ./loading.jl:128\n",
        " in reload_path at ./loading.jl:152\n",
        " in _require at ./loading.jl:67\n",
        " in require at ./loading.jl:54\n",
        " in include at ./boot.jl:249\n",
        " in include_from_node1 at ./loading.jl:128\n",
        " in reload_path at ./loading.jl:152\n",
        " in _require at ./loading.jl:67\n",
        " in require at ./loading.jl:54\n",
        " in include at ./boot.jl:249\n",
        " in include_from_node1 at ./loading.jl:128\n",
        " in include at ./boot.jl:249\n",
        " in include_from_node1 at ./loading.jl:128\n",
        " in reload_path at ./loading.jl:152\n",
        " in _require at ./loading.jl:67\n",
        " in require at ./loading.jl:52\n",
        " in include_string at loading.jl:97\n",
        " in execute_request_0x535c5df2 at /home/wheel/oxinabox/.julia/v0.4/IJulia/src/execute_request.jl:140\n",
        " in eventloop at /home/wheel/oxinabox/.julia/v0.4/IJulia/src/IJulia.jl:123\n",
        " in anonymous at task.jl:344\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function pz(x)\n",
      "    println(typeof(x), ' ', size(x))\n",
      "end\n",
      "\n",
      "function cols(x::Matrix)\n",
      "    function _it()\n",
      "        for ii in 1:size(x,2)\n",
      "            produce(x[:,ii])\n",
      "        end\n",
      "    end\n",
      "    Task(_it)\n",
      "end\n",
      "\n",
      "function rows(x::Matrix)\n",
      "    function _it()\n",
      "        for ii in 1:size(x,1)\n",
      "            produce(x[ii,:])\n",
      "        end\n",
      "    end\n",
      "    Task(_it)\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "rows (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function remove_rows_with_blank(df, colname)\n",
      "    df = df[!isna(df[colname]),:]\n",
      "    df = df[bool(map(x->!isempty(x), df[colname])),:]\n",
      "    df\n",
      "end\n",
      "    \n",
      "\n",
      "function load_con_data(name)\n",
      "    con = readtable(\"con_data/$name.csv\")\n",
      "    con = remove_rows_with_blank(con, :description)\n",
      "    #con = remove_rows_with_blank(con, :people)\n",
      "    \n",
      "    con[:con_name] = name\n",
      "    con\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "load_con_data (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con = [\n",
      "    load_con_data(\"swancon_2009\");\n",
      "    load_con_data(\"swancon_2010\");\n",
      "    load_con_data(\"swancon_2012\");\n",
      "    load_con_data(\"swancon_2013\");\n",
      "    load_con_data(\"swancon_2014\");];"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type TermResolver\n",
      "    vocab::Set{String} \n",
      "    index::Dict{String, Int64}\n",
      "end\n",
      "\n",
      "function TermResolver(wordFile::String=\"/usr/share/dict/words\" )\n",
      "    terms = Set{String}(map(x-> x |> lowercase|> strip, eachline(open(wordFile))))\n",
      "    term_indexes = [ww=>ind for (ind, ww) in enumerate(terms)]\n",
      "    TermResolver(terms, term_indexes)\n",
      "end\n",
      "\n",
      "terms = TermResolver(\"con_vocab.txt\")\n",
      "#terms = TermResolver(\"con_people.txt\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function strip_afixes(word,\n",
      "    suffixes = [\" \", \"_\",\"*\",\",\",\";\",\".\", \"!\", \"*\", \"...\", \"?\", \":\",\")\", \"\\\"\", \"'\", \"\"],\n",
      "    prefixes = [\" \", \"_\",\"*\",\"(\", \"\\\"\", \"'\", \"\"])\n",
      "       \n",
      "    assert(\"\" == suffixes[end])\n",
      "    assert(\"\" == prefixes[end])\n",
      " \n",
      "    for pre in prefixes, suf in suffixes #The straight word is covered by the prefix and suffix \"\"\n",
      "        if pre==suf==\"\"         \n",
      "            break\n",
      "        end\n",
      "        \n",
      "        if startswith(word,pre) && endswith(word,suf)\n",
      "            word = word[1+length(pre):end-length(suf)]\n",
      "            #println(\"***[$pre][$word][$suf]\")\n",
      "            word = strip_afixes(word,suffixes,prefixes)\n",
      "            break\n",
      "        end\n",
      "     end\n",
      "     word\n",
      "end\n",
      "    \n",
      "\n",
      "@doc \"\"\"\n",
      "    Breaks up text, in to a list of words.\n",
      "    It will make all words lowercase.\n",
      "    It will delete the suffix and prefixes into seperate words \n",
      "    if this causes the base word to be in the preffered words list.\n",
      "    \n",
      "    it will return preffered words in the first list \n",
      "    and unperferred words only in the second list\n",
      "\"\"\" ->\n",
      "function breakup_text(  text::String, \n",
      "    preferred_words::Set{String},\n",
      "    delims = [' ', '\\t','\\n','\\v', '\\f', '\\r']\n",
      "    )\n",
      "\n",
      "    \n",
      "    unpreferred_words = Array{String}(0)\n",
      "    words = Array{String}(0)\n",
      "    for field in split(text,delims)\n",
      "        found = false\n",
      "        field = lowercase(field)\n",
      "        word = strip_afixes(field)\n",
      "        if !isempty(word)\n",
      "            if word in preferred_words\n",
      "                push!(words,word)\n",
      "            else\n",
      "                push!(unpreferred_words,word) #but also note it as a problem\n",
      "            end\n",
      "        end\n",
      "\n",
      "        \n",
      "    end\n",
      "    words, unpreferred_words\n",
      "end\n",
      "\n",
      "function breakup_text(::DataArrays.NAtype, ::Set{AbstractString}, ::Any)\n",
      "    [],[] #No text becomes Empty Lists of words\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "breakup_text (generic function with 3 methods)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function get_all_terms(documents::Union(DataVector{String},DataVector{UTF8String}),\n",
      "                       delims=[' ', '\\t','\\n','\\v', '\\f', '\\r']\n",
      "    )\n",
      "    empty_vocab = Set{String}()\n",
      "    vocab = Set{String}()\n",
      "     \n",
      "    mapfoldl(doc-> breakup_text(doc,empty_vocab,delims)[2],\n",
      "              union,\n",
      "              Set{String}(),                \n",
      "              documents)\n",
      "end\n",
      "#terms =  get_all_terms(con[:description])\n",
      "#writedlm(\"con_vocab.txt\", terms)\n",
      "\n",
      "#people =  get_all_terms(con[:people],[','])\n",
      "#writedlm(\"con_people.txt\", people)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "get_all_terms (generic function with 2 methods)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function get_term_doc_matrix(\n",
      "        term_resolver::TermResolver, \n",
      "        documents::Union(DataVector{String},DataVector{UTF8String}),\n",
      "        delims=[' ', '\\t','\\n','\\v', '\\f', '\\r']\n",
      "    )\n",
      "    \n",
      "    TD = spzeros(length(term_resolver.vocab),length(documents)) #Term Rows, document columns\n",
      "    \n",
      "    missed_terms::Vector{String} = []\n",
      "    \n",
      "    for (iiDoc, doc) in enumerate(documents)\n",
      "        doc_terms::Vector{String}, doc_missed_terms = \n",
      "        breakup_text(doc, term_resolver.vocab, delims)\n",
      "        for term in doc_terms\n",
      "            iiTerm = term_resolver.index[term]\n",
      "            TD[iiTerm, iiDoc]+=1\n",
      "        end      \n",
      "        append!(missed_terms, doc_missed_terms)\n",
      "    end\n",
      "    TD, missed_terms\n",
      "end\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "get_term_doc_matrix (generic function with 2 methods)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "term_doc, missied_words = get_term_doc_matrix(terms, con[:description])\n",
      "#term_doc, missied_words = get_term_doc_matrix(terms, con[:people], [','])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(\n",
        "5468x715 sparse matrix with 23529 Float64 entries:\n",
        "\t[276 ,    1]  =  1.0\n",
        "\t[385 ,    1]  =  1.0\n",
        "\t[450 ,    1]  =  1.0\n",
        "\t[728 ,    1]  =  2.0\n",
        "\t[1173,    1]  =  1.0\n",
        "\t[1229,    1]  =  1.0\n",
        "\t[1655,    1]  =  1.0\n",
        "\t[1852,    1]  =  1.0\n",
        "\t[2080,    1]  =  1.0\n",
        "\t[2343,    1]  =  1.0\n",
        "\t\u22ee\n",
        "\t[3903,  715]  =  1.0\n",
        "\t[4218,  715]  =  1.0\n",
        "\t[4953,  715]  =  1.0\n",
        "\t[5179,  715]  =  5.0\n",
        "\t[5201,  715]  =  1.0\n",
        "\t[5261,  715]  =  1.0\n",
        "\t[5308,  715]  =  1.0\n",
        "\t[5331,  715]  =  1.0\n",
        "\t[5338,  715]  =  1.0\n",
        "\t[5400,  715]  =  1.0\n",
        "\t[5424,  715]  =  1.0,\n",
        "\n",
        "AbstractString[\"enemy?\\\"--cantra\"])"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using HDF5, JLD\n",
      "#@load \"term_doc.jld\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function pLSA_EM_train(X, K, max_iter=100, min_likelihood_change=1)\n",
      "    m  = size(X,1) # vocabulary size\n",
      "    nd = size(X,2) # number of documents\n",
      "    Pz,Pd_z,Pw_z = pLSA_init(m,nd,K)\n",
      "\n",
      "    past_likelyhoods = []\n",
      "    for ii in 1:max_iter\n",
      "        #Estimate\n",
      "        Pz_dw = pLSA_Estep(Pw_z,Pd_z,Pz)\n",
      "        \n",
      "        #Maximise\n",
      "        Pw_z,Pd_z,Pz = pLSA_Mstep(X,Pz_dw)\n",
      "        \n",
      "        # Evaluate data log-likelihood\n",
      "        likelyhood = pLSA_logL(X,Pw_z,Pz,Pd_z)  \n",
      "        \n",
      "        push!(past_likelyhoods,likelyhood)\n",
      "       \n",
      "        if rem(ii,10)==0\n",
      "            println(\"iteration: $ii, loglikelyhood $likelyhood\")\n",
      "        end\n",
      "        if ii>1 && (abs(past_likelyhoods[ii]-past_likelyhoods[ii-1]))<min_likelihood_change\n",
      "            #converged\n",
      "            break\n",
      "        end      \n",
      "    end\n",
      "    Pw_z,Pd_z,Pz, past_likelyhoods\n",
      "end\n",
      "\n",
      "\n",
      "function pLSA_init(m,nd,K)\n",
      "    Pz   = ones(K,1)/K # uniform prior on topics\n",
      "        \n",
      "    function rand_prob_mat(sz1,sz2)\n",
      "        P =  rand(sz1,sz2)   # word probabilities conditioned on topic\n",
      "        P./= sum(P,1)\n",
      "    end\n",
      "\n",
      "    Pw_z = rand_prob_mat(m,K)\n",
      "    Pd_z = rand_prob_mat(nd,K)\n",
      "\n",
      "    Pz,Pd_z,Pw_z\n",
      "end \n",
      "\n",
      "@fastmath function pLSA_Estep(Pw_z::Array{Float64,2}, Pd_z::Array{Float64,2}, Pz::Array{Float64,2})\n",
      "    K = size(Pw_z,2)\n",
      "    m = size(Pw_z,1)\n",
      "    nd = size(Pd_z,1)\n",
      "\n",
      "    Pz_dw = Array{Float64}((m,nd,K))\n",
      "\n",
      "    @simd for k in 1:K\n",
      "        @inbounds Pz_dw[:,:,k] = Pw_z[:,k] * Pd_z[:,k]' * Pz[k]\n",
      "    end;  \n",
      "\n",
      "    C = sum(Pz_dw,3)\n",
      "    @simd for k = 1:K    # normalize posterior\n",
      "        @inbounds Pz_dw[:,:,k] ./ C\n",
      "    end  \n",
      "    Pz_dw\n",
      "end\n",
      "\n",
      "@fastmath function pLSA_Mstep(X::Array{Float64,2},Pz_dw::Array{Float64,3})\n",
      "    K = size(Pz_dw,3)\n",
      "    nd = size(Pz_dw,2)\n",
      "    m = size(Pz_dw,1)\n",
      "    \n",
      "    Pw_z = Array{Float64}((m,K))\n",
      "    @simd for k in 1:K\n",
      "        @inbounds Pw_z[:,k] = sum(X .* Pz_dw[:,:,k],2)\n",
      "    end\n",
      "\n",
      "    Pd_z = Array{Float64}((nd,K))\n",
      "    @simd for k in 1:K\n",
      "        @inbounds Pd_z[:,k] = sum(X.* Pz_dw[:,:,k],1)'\n",
      "    end\n",
      "\n",
      "    Pz = sum(Pd_z,1)\n",
      "    #normalize to sum to 1\n",
      "    Pw_z./=sum(Pw_z,1)\n",
      "    Pd_z./=sum(Pd_z,1)\n",
      "    Pz  ./=sum(Pz,2)\n",
      "\n",
      "    Pw_z,Pd_z,Pz\n",
      "end\n",
      "\n",
      "@fastmath function pLSA_logL(X::Array{Float64,2},\n",
      "                             Pw_z::Array{Float64,2},\n",
      "                             Pz::Array{Float64,2},\n",
      "                             Pd_z::Array{Float64,2})\n",
      "    \n",
      "    sum(X .* log(Pw_z .*Pz * Pd_z'+eps())) \n",
      "end\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "pLSA_logL (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Pw_z,Pd_z,Pz, past_likelyhoods = pLSA_EM_train(full(term_doc), 3)\n",
      "\n",
      "Pd_w = Pd_z.*Pz*Pw_z'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "iteration: 10, loglikelyhood -1.007600490809826e6\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Pd_z'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "WARNING: deprecated syntax \"[a=>b, ...]\" at /home/wheel/oxinabox/.julia/v0.4/IJulia/src/inline.jl:23.\n",
        "Use \"Dict(a=>b, ...)\" instead.\n"
       ]
      },
      {
       "ename": "LoadError",
       "evalue": "LoadError: UndefVarError: Pd_w not defined\nwhile loading In[1], in expression starting on line 1",
       "output_type": "pyerr",
       "traceback": [
        "LoadError: UndefVarError: Pd_w not defined\nwhile loading In[1], in expression starting on line 1",
        ""
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@fastmath function getGweights(term_doc::SparseMatrixCSC{Float64,Int64})\n",
      "    global_freq = sum(term_doc,2)\n",
      "    @inbounds global_freq[global_freq.==0.0] = 1.0 #Avoid Nans\n",
      "    \n",
      "    P = term_doc./global_freq   \n",
      "    P = sparse(P)\n",
      "    \n",
      "    ps = nonzeros(P)\n",
      "    ps = ps.*log2(ps)\n",
      "    G = 1+sum(P,2)./log2(size(term_doc,2))\n",
      "    \n",
      "    G[:]\n",
      "end\n",
      "\n",
      "@fastmath function getLweights(term_doc::SparseMatrixCSC{Float64,Int64})\n",
      "    L = copy(term_doc)\n",
      "    ls = nonzeros(L)\n",
      "    ls = log2(1+ls)\n",
      "    L\n",
      "end\n",
      "\n",
      "function getWeight(term_doc::SparseMatrixCSC{Float64,Int64})\n",
      "    G =  getGweights(term_doc)\n",
      "    L = getLweights(term_doc)\n",
      "\n",
      "    termInds, docInds, vals = findnz(L)\n",
      "    for idx in 1:length(vals)\n",
      "        @inbounds vals[idx] *= G[termInds[idx]]\n",
      "    end\n",
      "    A = sparse(termInds, docInds, vals)\n",
      "\n",
      "end \n",
      "\n",
      "A =  getWeight(term_doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(T, S, D, nconv, niter, nmult, resid) = svds(A; nsv=10)\n",
      "con[:desc_x] = D[:,1]\n",
      "con[:desc_y] = D[:,2]\n",
      "[con[:desc_x] con[:desc_y]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subcon=con\n",
      "#subcon = con[(con[:con_name].==\"swancon_2014\") | (con[:con_name].==\"swancon_2013\"),:]\n",
      "#subcon = con[con[:con_name].==\"swancon_2009\",:]\n",
      "p = plot(subcon, x=\"desc_x\", y=\"desc_y\", label=\"title\", color=\"con_name\", \n",
      "Geom.point, Geom.label(position=:centered, hide_overlaps=false), Theme(default_point_size=2px))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_dims = 5\n",
      "(T2, S2, D2, nconv22, niter2, nmult2, resid2) = svds(A; nsv=initial_dims);\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_dims = -1\n",
      "iterations = 150\n",
      "perplexity = 50\n",
      "\n",
      "\n",
      "println(\"D2 dimensions are: $(size(D2))\")\n",
      "Y = tsne(D2, 2, initial_dims, iterations, perplexity)\n",
      "println(\"Y dimensions are: $(size(Y))\")\n",
      "\n",
      "plot(x=Y[:,1], y=Y[:,2], color=con[:con_name], label=con[:title] ,Geom.point, Geom.label(position=:centered, hide_overlaps=false), Theme(default_point_size=2px))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#pLSA\n",
      "## References: \n",
      " ####[1] Thomas Hofmann: Probabilistic Latent Semantic Analysis, \n",
      " Proc. of the 15th Conf. on Uncertainty in Artificial Intelligence (UAI'99) \n",
      "#### [2] Thomas Hofmann: Unsupervised Learning by Probabilistic Latent Semantic\n",
      " Analysis, Machine Learning Journal, 42(1), 2001, pp.177.196 \n",
      "\n",
      "#### Josef Sivic\n",
      " josef@robots.ox.ac.uk\n",
      " 30/7/2004\n",
      "\n",
      "#### Extended by Rob Fergus\n",
      " fergus@csail.mit.edu\n",
      " 03/10/05\n",
      "\n",
      "#### Translated to Julia by Lyndon White\n",
      " lyndon.white@ucc.gu.uwa.edu.au\n",
      " 24/02/15"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}